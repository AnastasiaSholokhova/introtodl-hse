{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6191b665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "991ddd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class Module\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(28*28*1,64),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.BatchNorm1d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64,32),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.BatchNorm1d(32),\n",
    "        nn.Sigmoid())\n",
    "    def forward(self,x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69ade206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a7470ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bb0d8bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = Model().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.01,momentum=0.9)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "18d0d08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=64, bias=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (6): Dropout(p=0.5, inplace=False)\n",
       "    (7): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8be9e6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 3.240\n",
      "Loss after mini-batch  1000: 3.120\n",
      "Loss after mini-batch  1500: 3.055\n",
      "Loss after mini-batch  2000: 3.006\n",
      "Loss after mini-batch  2500: 2.970\n",
      "Loss after mini-batch  3000: 2.944\n",
      "Loss after mini-batch  3500: 2.918\n",
      "Loss after mini-batch  4000: 2.900\n",
      "Loss after mini-batch  4500: 2.884\n",
      "Loss after mini-batch  5000: 2.874\n",
      "Loss after mini-batch  5500: 2.867\n",
      "Loss after mini-batch  6000: 2.859\n",
      "Starting epoch 2\n",
      "Loss after mini-batch   500: 2.852\n",
      "Loss after mini-batch  1000: 2.844\n",
      "Loss after mini-batch  1500: 2.841\n",
      "Loss after mini-batch  2000: 2.837\n",
      "Loss after mini-batch  2500: 2.835\n",
      "Loss after mini-batch  3000: 2.834\n",
      "Loss after mini-batch  3500: 2.839\n",
      "Loss after mini-batch  4000: 2.830\n",
      "Loss after mini-batch  4500: 2.828\n",
      "Loss after mini-batch  5000: 2.826\n",
      "Loss after mini-batch  5500: 2.823\n",
      "Loss after mini-batch  6000: 2.819\n",
      "Starting epoch 3\n",
      "Loss after mini-batch   500: 2.818\n",
      "Loss after mini-batch  1000: 2.818\n",
      "Loss after mini-batch  1500: 2.814\n",
      "Loss after mini-batch  2000: 2.814\n",
      "Loss after mini-batch  2500: 2.815\n",
      "Loss after mini-batch  3000: 2.813\n",
      "Loss after mini-batch  3500: 2.814\n",
      "Loss after mini-batch  4000: 2.809\n",
      "Loss after mini-batch  4500: 2.808\n",
      "Loss after mini-batch  5000: 2.808\n",
      "Loss after mini-batch  5500: 2.806\n",
      "Loss after mini-batch  6000: 2.810\n",
      "Starting epoch 4\n",
      "Loss after mini-batch   500: 2.804\n",
      "Loss after mini-batch  1000: 2.809\n",
      "Loss after mini-batch  1500: 2.807\n",
      "Loss after mini-batch  2000: 2.808\n",
      "Loss after mini-batch  2500: 2.805\n",
      "Loss after mini-batch  3000: 2.802\n",
      "Loss after mini-batch  3500: 2.805\n",
      "Loss after mini-batch  4000: 2.802\n",
      "Loss after mini-batch  4500: 2.804\n",
      "Loss after mini-batch  5000: 2.800\n",
      "Loss after mini-batch  5500: 2.800\n",
      "Loss after mini-batch  6000: 2.796\n",
      "Starting epoch 5\n",
      "Loss after mini-batch   500: 2.799\n",
      "Loss after mini-batch  1000: 2.797\n",
      "Loss after mini-batch  1500: 2.800\n",
      "Loss after mini-batch  2000: 2.796\n",
      "Loss after mini-batch  2500: 2.801\n",
      "Loss after mini-batch  3000: 2.797\n",
      "Loss after mini-batch  3500: 2.796\n",
      "Loss after mini-batch  4000: 2.798\n",
      "Loss after mini-batch  4500: 2.808\n",
      "Loss after mini-batch  5000: 2.798\n",
      "Loss after mini-batch  5500: 2.799\n",
      "Loss after mini-batch  6000: 2.797\n",
      "Starting epoch 6\n",
      "Loss after mini-batch   500: 2.797\n",
      "Loss after mini-batch  1000: 2.793\n",
      "Loss after mini-batch  1500: 2.794\n",
      "Loss after mini-batch  2000: 2.794\n",
      "Loss after mini-batch  2500: 2.794\n",
      "Loss after mini-batch  3000: 2.794\n",
      "Loss after mini-batch  3500: 2.795\n",
      "Loss after mini-batch  4000: 2.793\n",
      "Loss after mini-batch  4500: 2.791\n",
      "Loss after mini-batch  5000: 2.792\n",
      "Loss after mini-batch  5500: 2.790\n",
      "Loss after mini-batch  6000: 2.793\n",
      "Starting epoch 7\n",
      "Loss after mini-batch   500: 2.788\n",
      "Loss after mini-batch  1000: 2.791\n",
      "Loss after mini-batch  1500: 2.793\n",
      "Loss after mini-batch  2000: 2.794\n",
      "Loss after mini-batch  2500: 2.792\n",
      "Loss after mini-batch  3000: 2.791\n",
      "Loss after mini-batch  3500: 2.790\n",
      "Loss after mini-batch  4000: 2.788\n",
      "Loss after mini-batch  4500: 2.788\n",
      "Loss after mini-batch  5000: 2.788\n",
      "Loss after mini-batch  5500: 2.788\n",
      "Loss after mini-batch  6000: 2.790\n",
      "Starting epoch 8\n",
      "Loss after mini-batch   500: 2.788\n",
      "Loss after mini-batch  1000: 2.788\n",
      "Loss after mini-batch  1500: 2.788\n",
      "Loss after mini-batch  2000: 2.786\n",
      "Loss after mini-batch  2500: 2.787\n",
      "Loss after mini-batch  3000: 2.792\n",
      "Loss after mini-batch  3500: 2.794\n",
      "Loss after mini-batch  4000: 2.792\n",
      "Loss after mini-batch  4500: 2.788\n",
      "Loss after mini-batch  5000: 2.790\n",
      "Loss after mini-batch  5500: 2.789\n",
      "Loss after mini-batch  6000: 2.787\n",
      "Starting epoch 9\n",
      "Loss after mini-batch   500: 2.786\n",
      "Loss after mini-batch  1000: 2.787\n",
      "Loss after mini-batch  1500: 2.789\n",
      "Loss after mini-batch  2000: 2.789\n",
      "Loss after mini-batch  2500: 2.791\n",
      "Loss after mini-batch  3000: 2.788\n",
      "Loss after mini-batch  3500: 2.788\n",
      "Loss after mini-batch  4000: 2.787\n",
      "Loss after mini-batch  4500: 2.788\n",
      "Loss after mini-batch  5000: 2.789\n",
      "Loss after mini-batch  5500: 2.783\n",
      "Loss after mini-batch  6000: 2.790\n",
      "Starting epoch 10\n",
      "Loss after mini-batch   500: 2.786\n",
      "Loss after mini-batch  1000: 2.788\n",
      "Loss after mini-batch  1500: 2.787\n",
      "Loss after mini-batch  2000: 2.784\n",
      "Loss after mini-batch  2500: 2.787\n",
      "Loss after mini-batch  3000: 2.785\n",
      "Loss after mini-batch  3500: 2.786\n",
      "Loss after mini-batch  4000: 2.787\n",
      "Loss after mini-batch  4500: 2.786\n",
      "Loss after mini-batch  5000: 2.782\n",
      "Loss after mini-batch  5500: 2.787\n",
      "Loss after mini-batch  6000: 2.788\n"
     ]
    }
   ],
   "source": [
    "# Run the training loop\n",
    "for epoch in range(0, 10):\n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "    # Set current loss value\n",
    "    current_loss = 0.0\n",
    "    # Iterate over the DataLoader for training data\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "      # Get inputs\n",
    "      inputs, targets = data\n",
    "      # Zero the gradients\n",
    "      optimizer.zero_grad()\n",
    "      # Perform forward pass\n",
    "      outputs = model(inputs)\n",
    "      # Compute loss\n",
    "      loss = loss_function(outputs, targets)\n",
    "      # Perform backward pass\n",
    "      loss.backward()\n",
    "      # Perform optimization\n",
    "      optimizer.step()\n",
    "      # Print statistics\n",
    "      current_loss += loss.item()\n",
    "      if i % 500 == 499:\n",
    "          print('Loss after mini-batch %5d: %.3f' %\n",
    "                (i + 1, current_loss / 500))\n",
    "          current_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa97aab7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
